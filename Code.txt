# -- coding: utf-8 --
from pyspark.sql import SparkSession
from pyspark.sql import Row
from pyspark.sql.functions import col,when,max

def parseInput(line):
        fields = line.split('|')
        return Row(user_id = int(fields[0]), age = int(fields [1]), gender = fields [2], occupation = fields[3], zip = fields[4])

def parse_rating(line):
        fields = line.split('\t')
        return Row(user_id = int(fields[0]), movie_id = int(fields [1]), rating= int(fields [2]), masa = int(fields[3]))

def parse_name(line):
        fields = line.split('|')
        return Row(movie_id = int(fields[0]), name = fields [1], release_date=fields[2],video_release_date=fields[3],imdb_url=fields[4],unknown=int(fields[5]),action=int(fields[6]),adventure=int(fields[7]),animation=int(fields[8]),children=int(fields[9]),comedy=int(fields[10]),crime=int(fields[11]),documentary=int(fields[12]),drama=int(fields[13]),fantasy=int(fields[14]),film_noir=int(fields[15]),horror=int(fields[16]),musical=int(fields[17]),mystery=int(fields[18]),romance=int(fields[19]),sci_fi=int(fields[20]),thriller=int(fields[21]),war=int(fields[22]),western=int(fields[23]))
if _name_ == "_main_":
        # Create a SparkSession
    spark = SparkSession.builder.appName("CassandraIntegration").config("spark.cassandra.connection.host", "127.0.0.1").getOrCreate()
    user = spark.sparkContext.textFile("hdfs:///user/maria_dev/ml-100k/u.user")
    rating =  spark.sparkContext.textFile("hdfs:///user/maria_dev/ml-100k/u.data")
    name =  spark.sparkContext.textFile("hdfs:///user/maria_dev/ml-100k/u.item")

    users = user.map(parseInput)
    ratings = rating.map(parse_rating)
    names = name.map(parse_name)

    usersDataset = spark.createDataFrame(users)
    ratingsDataset = spark.createDataFrame(ratings)
    namesDataset = spark.createDataFrame(names)

    usersDataset.write\
         .format("org.apache.spark.sql.cassandra")\
         .mode('append')\
         .options(table="users", keyspace="movielens")\
         .save()
    ratingsDataset.write\
         .format("org.apache.spark.sql.cassandra")\
         .mode('append')\
         .options(table="ratings", keyspace="movielens")\
         .save()
    namesDataset.write\
         .format("org.apache.spark.sql.cassandra")\
         .mode('append')\
         .options(table="movie_item", keyspace="movielens")\
         .save()

    readUsers = spark.read\
        .format("org.apache.spark.sql.cassandra")\
        .options(table="users", keyspace="movielens")\
        .load()
    readRatings = spark.read\
        .format("org.apache.spark.sql.cassandra")\
        .options(table="ratings", keyspace="movielens")\
        .load()
    readNames = spark.read\
        .format("org.apache.spark.sql.cassandra")\
        .options(table="movie_item", keyspace="movielens")\
        .load()

    readUsers.createOrReplaceTempView("users")
    readRatings.createOrReplaceTempView("ratings")
    readNames.createOrReplaceTempView("names")

movie_ratings = ratingsDataset.join(namesDataset,"movie_id")
movie_ratings.createOrReplaceTempView("movie_ratings")

print("The average rating for each movie.")
avg_ratings = spark.sql("SELECT name, AVG(rating) AS avg_rating FROM movie_ratings GROUP BY name")
avg_ratings.show(10,truncate=100)

print("The top ten movies with the highest average ratings.")
top_ten_movies = spark.sql("SELECT name, AVG(rating) AS avg_rating FROM movie_ratings GROUP BY name ORDER BY avg_rating DESC LIMIT 10")
top_ten_movies.show(truncate=100)

active_users = spark.sql("SELECT user_id, COUNT(movie_id) AS num_movies FROM movie_ratings GROUP BY user_id  HAVING num_movies >= 50")
active_user_ratings = active_users.join(ratingsDataset, "user_id").join(namesDataset, "movie_id")
genre_columns = ["action", "adventure", "animation", "children", "comedy", "crime", "documentary", "drama", "fantasy", "film_noir", "horror", "musical", "mystery", "romance", "sci_fi", "thriller", "war", "western"]
exprs = [max(when(col(genre) == 1, col("rating")).otherwise(0)).alias(genre) for genre in genre_columns]
favorite_genres = active_user_ratings.groupBy("user_id").agg(*exprs)
def find_favorite_genre(row):
    max_rating = 0
    favorite = None
    for genre in genre_columns:
        if row[genre] > max_rating:
            max_rating = row[genre]
            favorite = genre
    return (row['user_id'], favorite)
favorite_genres_rdd = favorite_genres.rdd.map(find_favorite_genre)
favorite_genres_df = spark.createDataFrame(favorite_genres_rdd, ["user_id", "favorite_genre"])
genre_popularity = favorite_genres_df.groupBy("favorite_genre").count()
print("The users who have rated at least 50 movies.")
active_users .show(10)
print("The users who have rated at least 50 movies and identify their favourite movie genres.")
favorite_genres_df .show(10)
genre_popularity .show()

print("The users with age that is less than 20 years old.")
young_users = spark.sql("SELECT * FROM users WHERE age < 20")
young_users.show(10,truncate=100)

print("The users who have the occupation scientist and their age is between 30 and 40 years old.")
scientists = spark.sql("SELECT * FROM users WHERE occupation = 'scientist' AND age BETWEEN 30 AND 40")
scientists.show(10,truncate=100)
spark.stop()
